{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "56f93412",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, count, desc, expr, lit, max, sum, udf\n",
    "from pyspark.sql.types import IntegerType, StringType, NumericType, StructField, StructType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.storagelevel import StorageLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa16ffe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/17 18:44:00 WARN Utils: Your hostname, MacBook-Air-de-Gabriel.local resolves to a loopback address: 127.0.0.1; using 192.168.1.8 instead (on interface en0)\n",
      "23/07/17 18:44:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/07/17 18:44:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "            .master(\"local[*]\")\n",
    "            .appName(\"Spark Documentation\")\n",
    "            .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfdc053",
   "metadata": {},
   "source": [
    "# Documentation topic order\n",
    "- SparkSession\n",
    "- SQLContext\n",
    "- UDFRegistration\n",
    "- DataFrame\n",
    "- GroupedData\n",
    "- Column\n",
    "- Catalog\n",
    "- Row\n",
    "- DataFrameNaFunctions\n",
    "- DataFrameStatFunctions\n",
    "- DataFrameReader\n",
    "- DataFrameWriter\n",
    "- CoGroupedData\n",
    "\n",
    "- Types\n",
    "- Functions\n",
    "- avro.Functions\n",
    "- Streaming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe0dc13b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_customers = spark.read.csv(\"../dataset/csv_data/olist_customers_dataset.csv\", inferSchema=True, header=True)\n",
    "df_orders = spark.read.csv(\"../dataset/csv_data/olist_orders_dataset.csv\", inferSchema=True, header=True)\n",
    "df_order_items = spark.read.csv(\"../dataset/csv_data/olist_order_items_dataset.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "06e8ebd4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/07/15 16:35:54 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[order_id: string, order_item_id: int, product_id: string, seller_id: string, shipping_limit_date: timestamp, price: double, freight_value: double]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_customers.cache()\n",
    "df_orders.cache()\n",
    "df_order_items.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ca5a9dff",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+\n",
      "|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date| price|freight_value|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+\n",
      "|00010242fe8c5a6d1...|            1|4244733e06e7ecb49...|48436dade18ac8b2b...|2017-09-19 09:45:35|  58.9|        13.29|\n",
      "|00018f77f2f0320c5...|            1|e5f2d52b802189ee6...|dd7ddc04e1b6c2c61...|2017-05-03 11:05:13| 239.9|        19.93|\n",
      "|000229ec398224ef6...|            1|c777355d18b72b67a...|5b51032eddd242adc...|2018-01-18 14:48:30| 199.0|        17.87|\n",
      "|00024acbcdf0a6daa...|            1|7634da152a4610f15...|9d7a1d34a50524090...|2018-08-15 10:10:18| 12.99|        12.79|\n",
      "|00042b26cf59d7ce6...|            1|ac6c3623068f30de0...|df560393f3a51e745...|2017-02-13 13:57:51| 199.9|        18.14|\n",
      "|00048cc3ae777c65d...|            1|ef92defde845ab845...|6426d21aca402a131...|2017-05-23 03:55:27|  21.9|        12.69|\n",
      "|00054e8431b9d7675...|            1|8d4f2bb7e93e6710a...|7040e82f899a04d1b...|2017-12-14 12:10:31|  19.9|        11.85|\n",
      "|000576fe39319847c...|            1|557d850972a7d6f79...|5996cddab893a4652...|2018-07-10 12:30:45| 810.0|        70.75|\n",
      "|0005a1a1728c9d785...|            1|310ae3c140ff94b03...|a416b6a846a117243...|2018-03-26 18:31:29|145.95|        11.65|\n",
      "|0005f50442cb953dc...|            1|4535b0e1091c278df...|ba143b05f0110f0dc...|2018-07-06 14:10:56| 53.99|         11.4|\n",
      "|00061f2a7bc09da83...|            1|d63c1011f49d98b97...|cc419e0650a3c5ba7...|2018-03-29 22:28:09| 59.99|         8.88|\n",
      "|00063b381e2406b52...|            1|f177554ea93259a5b...|8602a61d680a10a82...|2018-07-31 17:30:39|  45.0|        12.98|\n",
      "|0006ec9db01a64e59...|            1|99a4788cb24856965...|4a3ca9315b744ce9f...|2018-07-26 17:24:20|  74.0|        23.32|\n",
      "|0008288aa423d2a3f...|            1|368c6c730842d7801...|1f50f920176fa81da...|2018-02-21 02:55:52|  49.9|        13.37|\n",
      "|0008288aa423d2a3f...|            2|368c6c730842d7801...|1f50f920176fa81da...|2018-02-21 02:55:52|  49.9|        13.37|\n",
      "|0009792311464db53...|            1|8cab8abac59158715...|530ec6109d11eaaf8...|2018-08-17 12:15:10|  99.9|        27.65|\n",
      "|0009c9a17f916a706...|            1|3f27ac8e699df3d30...|fcb5ace8bcc92f757...|2018-05-02 09:31:53| 639.0|        11.34|\n",
      "|000aed2e25dbad2f9...|            1|4fa33915031a8cde0...|fe2032dab1a61af87...|2018-05-16 20:57:03| 144.0|         8.77|\n",
      "|000c3e6612759851c...|            1|b50c950aba0dcead2...|218d46b86c1881d02...|2017-08-21 03:33:13|  99.0|        13.71|\n",
      "|000e562887b1f2006...|            1|5ed9eaf534f6936b5...|8cbac7e12637ed9cf...|2018-02-28 12:08:37|  25.0|        16.11|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_order_items.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e83289ed",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|total_price|\n",
      "+-----------+\n",
      "|     6735.0|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|total_price|\n",
      "+-----------+\n",
      "|     6735.0|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|total_price|\n",
      "+-----------+\n",
      "|     6735.0|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|total_price|\n",
      "+-----------+\n",
      "|     6735.0|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|total_price|\n",
      "+-----------+\n",
      "|     6735.0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select columns in Dataframe\n",
    "df_order_items.price\n",
    "df_order_items['price']\n",
    "col('price')\n",
    "expr('price')\n",
    "\n",
    "df_order_items.select(max(df_order_items.price).alias('total_price')).show()\n",
    "df_order_items.select(max(df_order_items['price']).alias('total_price')).show()\n",
    "df_order_items.select(max(col('price')).alias('total_price')).show()\n",
    "df_order_items.select(max('price').alias('total_price')).show()\n",
    "df_order_items.select(expr('max(price)').alias('total_price')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "79f9eb0d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+------------------+\n",
      "|          product_id|sum(price)|sum(freight_value)|\n",
      "+--------------------+----------+------------------+\n",
      "|0b0172eb0fd18479d...|    404.28|            269.31|\n",
      "|42a2bd596fda1baef...|    1927.9|            364.31|\n",
      "+--------------------+----------+------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+-----------+-------------------+\n",
      "|          product_id|total_price|total_freight_value|\n",
      "+--------------------+-----------+-------------------+\n",
      "|0b0172eb0fd18479d...|     404.28|             269.31|\n",
      "|42a2bd596fda1baef...|     1927.9|             364.31|\n",
      "+--------------------+-----------+-------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+---------+\n",
      "|          product_id|min_price|\n",
      "+--------------------+---------+\n",
      "|0b0172eb0fd18479d...|    19.89|\n",
      "|42a2bd596fda1baef...|     79.9|\n",
      "+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+----------+\n",
      "|          product_id|min(price)|\n",
      "+--------------------+----------+\n",
      "|0b0172eb0fd18479d...|     19.89|\n",
      "|42a2bd596fda1baef...|      79.9|\n",
      "+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+---------+\n",
      "|          product_id|min_price|\n",
      "+--------------------+---------+\n",
      "|0b0172eb0fd18479d...|    19.89|\n",
      "|42a2bd596fda1baef...|     79.9|\n",
      "+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------+\n",
      "|qnt_rows|\n",
      "+--------+\n",
      "|  112650|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# agg, groupBy, alias\n",
    "df_order_items.groupBy('product_id').agg({'price': 'sum', 'freight_value': 'sum'}).show(2)\n",
    "df_order_items.groupBy('product_id').agg(sum('price').alias('total_price'), sum('freight_value').alias('total_freight_value')).show(2)\n",
    "df_order_items.groupBy('product_id').agg(expr('min(price)').alias('min_price')).show(2) # With expr, it's not necessary import functions\n",
    "df_order_items.groupBy(df_order_items.product_id).agg(expr('min(price)').alias('min_price')).show(2)\n",
    "df_order_items.agg(expr('count(*)').alias('qnt_rows')).show(2)\n",
    "df_order_items.groupBy('product_id').min('price').show(2) # This min method is from GroupedData class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b7381f16",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+---+----+----+----+----+----+---+-----+---+---+---+---+----+---+----+-----+---+---+---+----+----+---+-----+---+\n",
      "| AC| AL| AM| AP|  BA|  CE|  DF|  ES|  GO| MA|   MG| MS| MT| PA| PB|  PE| PI|  PR|   RJ| RN| RO| RR|  RS|  SC| SE|   SP| TO|\n",
      "+---+---+---+---+----+----+----+----+----+---+-----+---+---+---+---+----+---+----+-----+---+---+---+----+----+---+-----+---+\n",
      "| 81|413|148| 68|3380|1336|2140|2033|2020|747|11635|715|907|975|536|1652|495|5045|12852|485|253| 46|5466|3637|350|41746|280|\n",
      "+---+---+---+---+----+----+----+----+----+---+-----+---+---+---+---+----+---+----+-----+---+---+---+----+----+---+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# GroupedData.pivot\n",
    "df_customers.groupBy().pivot('customer_state').agg(count('*')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b8b852d4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|          product_id|min_price|\n",
      "+--------------------+---------+\n",
      "|0b0172eb0fd18479d...|    19.89|\n",
      "|42a2bd596fda1baef...|     79.9|\n",
      "+--------------------+---------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+---------+\n",
      "|min_price|\n",
      "+---------+\n",
      "|    19.89|\n",
      "|     79.9|\n",
      "+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_order_items\n",
    "     .select('order_id', 'product_id', 'price')\n",
    "     .groupBy('product_id')\n",
    "     .agg(expr('min(price)').alias('min_price'))\n",
    "     .show(2))\n",
    "\n",
    "(df_order_items\n",
    "     .select('order_id', 'product_id', 'price')\n",
    "     .groupBy('product_id')\n",
    "     .agg(expr('min(price)').alias('min_price'))\n",
    "     .select('min_price')\n",
    "     .show(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1d1c95ca",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------+-----+\n",
      "|customer_state|state_cat|count|\n",
      "+--------------+---------+-----+\n",
      "|            SC|    false| 3637|\n",
      "|            SP|     true|41746|\n",
      "+--------------+---------+-----+\n",
      "\n",
      "+--------------+---------+-----+\n",
      "|customer_state|state_cat|count|\n",
      "+--------------+---------+-----+\n",
      "|            SC|        0| 3637|\n",
      "|            SP|        1|41746|\n",
      "+--------------+---------+-----+\n",
      "\n",
      "+--------------+---------+-----+\n",
      "|customer_state|state_cat|count|\n",
      "+--------------+---------+-----+\n",
      "|            SC|        0| 3637|\n",
      "|            SP|        1|41746|\n",
      "+--------------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# expr inside select\n",
    "(df_customers\n",
    "     .where(col('customer_state').isin('SC', 'SP'))\n",
    "     .select('customer_state', expr('CASE WHEN customer_state = \"SP\" THEN TRUE ELSE FALSE END').alias('state_cat'))\n",
    "     .groupBy('customer_state', 'state_cat')\n",
    "     .agg(count(\"*\").alias('count'))\n",
    "     .show())\n",
    "\n",
    "# expr using selectExpr\n",
    "(df_customers\n",
    "     .where(col('customer_state').isin('SC', 'SP'))\n",
    "     .selectExpr('customer_state', 'CASE WHEN customer_state = \"SP\" THEN 1 ELSE 0 END AS state_cat')\n",
    "     .groupBy('customer_state', 'state_cat')\n",
    "     .agg(count(\"*\").alias('count'))\n",
    "     .show())\n",
    "\n",
    "# expr inside groupBy\n",
    "(df_customers\n",
    "     .where(col('customer_state').isin('SC', 'SP'))\n",
    "     .groupBy('customer_state', expr('CASE WHEN customer_state = \"SP\" THEN 1 ELSE 0 END').alias('state_cat'))\n",
    "     .agg(count(\"*\").alias('count'))\n",
    "     .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "59bd85b2",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|          product_id|sum(price)|\n",
      "+--------------------+----------+\n",
      "|0b0172eb0fd18479d...|    404.28|\n",
      "|42a2bd596fda1baef...|    1927.9|\n",
      "+--------------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(df_order_items\n",
    "     .groupBy('product_id')\n",
    "     .sum('price')\n",
    "     .show(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "df66098b",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------+--------------------+--------------+--------+\n",
      "|         customer_id|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|novo_zip|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+--------+\n",
      "|06b8999e2fba1a1fb...|861eff4711a542e4b...|                   14409|              franca|            SP|   14410|\n",
      "|18955e83d337fd6b2...|290c77bc529b7ac93...|                    9790|sao bernardo do c...|            SP|    9791|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+--------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+--------+\n",
      "|         customer_id|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|novo_zip|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+--------+\n",
      "|06b8999e2fba1a1fb...|861eff4711a542e4b...|                   14409|              franca|            SP|   14410|\n",
      "|18955e83d337fd6b2...|290c77bc529b7ac93...|                    9790|sao bernardo do c...|            SP|    9791|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# withColumn\n",
    "df_customers.withColumn('novo_zip', expr('customer_zip_code_prefix + 1')).show(2)\n",
    "df_customers.withColumn('novo_zip', col('customer_zip_code_prefix') + 1).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "218016bf",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|square|\n",
      "+------+\n",
      "|     9|\n",
      "+------+\n",
      "\n",
      "+------+\n",
      "|square|\n",
      "+------+\n",
      "|    16|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UDF register\n",
    "f = lambda x: x**2\n",
    "\n",
    "# Register from a python function\n",
    "spark.udf.register('py_square', udf_square)\n",
    "spark.sql('SELECT py_square(3) AS square').show()\n",
    "\n",
    "# Register from an UDF\n",
    "udf_square = udf(f, IntegerType())\n",
    "spark.udf.register('udf_square', udf_square)\n",
    "spark.sql('SELECT udf_square(4) AS square').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "37b81b8d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|integer_lit|\n",
      "+-----------+\n",
      "|         16|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|integer_lit|\n",
      "+-----------+\n",
      "|         25|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|integer_lit|\n",
      "+-----------+\n",
      "|         36|\n",
      "+-----------+\n",
      "\n",
      "+-----------+\n",
      "|integer_lit|\n",
      "+-----------+\n",
      "|         49|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# UDF\n",
    "f = lambda x: x**2\n",
    "udf_square = udf(f, IntegerType()).asNondeterministic()\n",
    "df_customers.select(udf_square(lit(4)).alias('integer_lit')).distinct().show()\n",
    "\n",
    "# UDF function\n",
    "def func(x):\n",
    "    return x**2\n",
    "\n",
    "udf_square = udf(func, IntegerType())\n",
    "df_customers.select(udf_square(lit(5)).alias('integer_lit')).distinct().show()\n",
    "\n",
    "# UDF annotation\n",
    "@udf\n",
    "def func(x):\n",
    "    return x**2\n",
    "\n",
    "df_customers.select(func(lit(6)).alias('integer_lit')).distinct().show()\n",
    "\n",
    "@udf(returnType=StringType())\n",
    "def func(x):\n",
    "    return x**2\n",
    "\n",
    "df_customers.select(func(lit(7)).alias('integer_lit')).distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "8e85e805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coalesce, Repartition\n",
    "\n",
    "df_customers.rdd.getNumPartitions()\n",
    "df_customers.coalesce(2).rdd.getNumPartitions()\n",
    "df_customers.repartition(4).rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1f6708e6",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "|         customer_id|  customer_unique_id|customer_zip_code_prefix|       customer_city|customer_state|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "|06b8999e2fba1a1fb...|861eff4711a542e4b...|                   14409|              franca|            SP|\n",
      "|18955e83d337fd6b2...|290c77bc529b7ac93...|                    9790|sao bernardo do c...|            SP|\n",
      "+--------------------+--------------------+------------------------+--------------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Temp View - Live during Spark Application\n",
    "df_customers.createOrReplaceGlobalTempView('view_temp_customers')\n",
    "spark.sql(\"SELECT * FROM global_temp.view_temp_customers\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8f02d99",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+------+------+\n",
      "|    _1|    _2|\n",
      "+------+------+\n",
      "|  Java| 20000|\n",
      "|Python|100000|\n",
      "| Scala|  3000|\n",
      "+------+------+\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+--------+-----------+\n",
      "|language|users_count|\n",
      "+--------+-----------+\n",
      "|    Java|      20000|\n",
      "|  Python|     100000|\n",
      "|   Scala|       3000|\n",
      "+--------+-----------+\n",
      "\n",
      "+---+-------+\n",
      "|age|   name|\n",
      "+---+-------+\n",
      "|  1|  Alice|\n",
      "| 34|Gabriel|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# createDataFrame\n",
    "schema = StructType([\n",
    "    StructField('language', StringType(), False),\n",
    "    StructField('users_count', IntegerType(), False)\n",
    "])\n",
    "columns = [\"language\", \"users_count\"]\n",
    "data_list = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
    "data_row = [Row(\"Java\", 20000), Row(\"Python\", 100000), Row(\"Scala\", 3000)]\n",
    "data_dict = [{'name': 'Alice', 'age': 1}, {'name': 'Gabriel', 'age': 34}]\n",
    "data_dict_nested = [{'name': 'Alice', 'age': 1}, {'name': 'Gabriel', 'age': 34}]\n",
    "\n",
    "# Create from RDD with toDF\n",
    "rdd = spark.sparkContext.parallelize(data_list)\n",
    "rdd.toDF(columns).show()\n",
    "# Create from RDD with createDataFrame and column name\n",
    "spark.createDataFrame(rdd).toDF(*columns).show()\n",
    "# Create from RDD with createDataFrame and column name\n",
    "spark.createDataFrame(rdd, schema).show()\n",
    "# Create from list with createDataFrame and column name\n",
    "spark.createDataFrame(data_list).toDF(*columns).show()\n",
    "# Create from list\n",
    "spark.createDataFrame(data_list, columns).show()\n",
    "# Create from list without schema\n",
    "spark.createDataFrame(data_row).show()\n",
    "# Create from list with schema\n",
    "spark.createDataFrame(data_row, schema).show()\n",
    "# Create from Row with columns\n",
    "spark.createDataFrame(data_row, columns).show()\n",
    "# Create from Row with schema\n",
    "spark.createDataFrame(data_row, schema).show()\n",
    "# Criar a partir de dicionário\n",
    "spark.createDataFrame(data_dict).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "edaa8a9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- firstname: string (nullable = true)\n",
      " |    |-- middlename: string (nullable = true)\n",
      " |    |-- lastname: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+------+------+\n",
      "|name                |id   |gender|salary|\n",
      "+--------------------+-----+------+------+\n",
      "|{James, , Smith}    |36636|M     |3100  |\n",
      "|{Michael, Rose, }   |40288|M     |4300  |\n",
      "|{Robert, , Williams}|42114|M     |1400  |\n",
      "|{Maria, Anne, Jones}|39192|F     |5500  |\n",
      "|{Jen, Mary, Brown}  |     |F     |-1    |\n",
      "+--------------------+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "structureData = [\n",
    "    ((\"James\",\"\",\"Smith\"),\"36636\",\"M\",3100),\n",
    "    ((\"Michael\",\"Rose\",\"\"),\"40288\",\"M\",4300),\n",
    "    ((\"Robert\",\"\",\"Williams\"),\"42114\",\"M\",1400),\n",
    "    ((\"Maria\",\"Anne\",\"Jones\"),\"39192\",\"F\",5500),\n",
    "    ((\"Jen\",\"Mary\",\"Brown\"),\"\",\"F\",-1)\n",
    "  ]\n",
    "structureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('middlename', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('id', StringType(), True),\n",
    "         StructField('gender', StringType(), True),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])\n",
    "\n",
    "df_names = spark.createDataFrame(data=structureData,schema=structureSchema)\n",
    "df_names.printSchema()\n",
    "df_names.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3f283909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write\n",
    "df_customers.write.saveAsTable('table_temp_customers')\n",
    "df_customers.write.format('parquet').mode('overwrite').save(\"../dataset/parquet_data/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af8c8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crossJoin, withColumn, withColumnRenamed\n",
    "df_x = spark.range(10).withColumnRenamed('id', 'c_x')\n",
    "df_y = spark.range(10).withColumnRenamed('id', 'c_y')\n",
    "df_result = df_x.crossJoin(df_y).withColumn('result', col('c_x') * col('c_y'))\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b8181bab",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 113:>                                                        (0 + 3) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|customer_state_customer_state| AC| AL| AM| AP| BA| CE| DF| ES| GO| MA| MG| MS| MT| PA| PB| PE| PI| PR| RJ| RN| RO| RR| RS| SC| SE| SP| TO|\n",
      "+-----------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "|                           AC|  8|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           AL|  0| 68|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           AM|  0|  0|  5|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           AP|  0|  0|  0|  6|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           BA|  0|  0|  0|  0|353|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           CE|  0|  0|  0|  0|  0|161|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           DF|  0|  0|  0|  0|  0|  0|  6|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           ES|  0|  0|  0|  0|  0|  0|  0| 95|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           GO|  0|  0|  0|  0|  0|  0|  0|  0|178|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           MA|  0|  0|  0|  0|  0|  0|  0|  0|  0|122|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           MG|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|745|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           MS|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0| 67|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           MT|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|101|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           PA|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0| 89|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           PB|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0| 92|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           PE|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|152|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           PI|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0| 72|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           PR|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|364|  0|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           RJ|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|149|  0|  0|  0|  0|  0|  0|  0|  0|\n",
      "|                           RN|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0| 90|  0|  0|  0|  0|  0|  0|  0|\n",
      "+-----------------------------+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# crossTab, orderBy, distinct\n",
    "(df_customers\n",
    "     .select('customer_state', 'customer_city')\n",
    "     .distinct()\n",
    "     .crosstab('customer_state', 'customer_state')\n",
    "     .orderBy(col('customer_state_customer_state'))\n",
    "     .show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f76b8894",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|             price|\n",
      "+-------+------------------+\n",
      "|  count|            112650|\n",
      "|   mean|120.65373901464174|\n",
      "| stddev| 183.6339280502595|\n",
      "|    min|              0.85|\n",
      "|    max|            6735.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# describe\n",
    "df_order_items.describe('price').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04102452",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+\n",
      "|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date|price|freight_value|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+\n",
      "|00010242fe8c5a6d1...|            1|4244733e06e7ecb49...|48436dade18ac8b2b...|2017-09-19 09:45:35| 58.9|        13.29|\n",
      "|00018f77f2f0320c5...|            1|e5f2d52b802189ee6...|dd7ddc04e1b6c2c61...|2017-05-03 11:05:13|239.9|        19.93|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+\n",
      "|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date|price|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+\n",
      "|00010242fe8c5a6d1...|            1|4244733e06e7ecb49...|48436dade18ac8b2b...|2017-09-19 09:45:35| 58.9|\n",
      "|00018f77f2f0320c5...|            1|e5f2d52b802189ee6...|dd7ddc04e1b6c2c61...|2017-05-03 11:05:13|239.9|\n",
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# drop\n",
    "df_order_items.show(2)\n",
    "df_order_items.drop('freight_value').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2cdece86",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AC|   81|\n",
      "|            AM|  148|\n",
      "|            AP|   68|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AC|   81|\n",
      "|          null|  413|\n",
      "|            AM|  148|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AC|   81|\n",
      "|          null|  413|\n",
      "|            AM|  148|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AC|   81|\n",
      "|          null|  413|\n",
      "|            AM|  148|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AC|   81|\n",
      "|            AM|  148|\n",
      "|            AP|   68|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dropna > na.drop\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .dropna()\n",
    "    .show(3))\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .dropna(subset=['count'])\n",
    "    .show(3))\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .dropna(how='all')\n",
    "    .show(3))\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .dropna(thresh=1)\n",
    "    .show(3))\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .dropna(thresh=2)\n",
    "    .show(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "1bd243e7",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AC|   81|\n",
      "|       Unknown|  413|\n",
      "|            AM|  148|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|customer_state|count|\n",
      "+--------------+-----+\n",
      "|            AC|   81|\n",
      "|          null|  413|\n",
      "|            AM|  148|\n",
      "+--------------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fillna > na.fill\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .fillna('Unknown')\n",
    "    .show(3))\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .fillna('Unknown', ['count'])\n",
    "    .show(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1796ea35",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (9)\n",
      "+- Project (8)\n",
      "   +- Sort (7)\n",
      "      +- Exchange (6)\n",
      "         +- Filter (5)\n",
      "            +- HashAggregate (4)\n",
      "               +- Exchange (3)\n",
      "                  +- HashAggregate (2)\n",
      "                     +- Scan csv  (1)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [1]: [customer_state#105]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/Users/gabrielbossardi/Documents/Projects/pyspark-overview/dataset/csv_data/olist_customers_dataset.csv]\n",
      "ReadSchema: struct<customer_state:string>\n",
      "\n",
      "(2) HashAggregate\n",
      "Input [1]: [customer_state#105]\n",
      "Keys [1]: [customer_state#105]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#8394L]\n",
      "Results [2]: [customer_state#105, count#8395L]\n",
      "\n",
      "(3) Exchange\n",
      "Input [2]: [customer_state#105, count#8395L]\n",
      "Arguments: hashpartitioning(customer_state#105, 200), ENSURE_REQUIREMENTS, [plan_id=4739]\n",
      "\n",
      "(4) HashAggregate\n",
      "Input [2]: [customer_state#105, count#8395L]\n",
      "Keys [1]: [customer_state#105]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#8383L]\n",
      "Results [2]: [customer_state#105, count(1)#8383L AS count#8384L]\n",
      "\n",
      "(5) Filter\n",
      "Input [2]: [customer_state#105, count#8384L]\n",
      "Condition : atleastnnonnulls(2, CASE WHEN (customer_state#105 = AL) THEN null ELSE customer_state#105 END, count#8384L)\n",
      "\n",
      "(6) Exchange\n",
      "Input [2]: [customer_state#105, count#8384L]\n",
      "Arguments: rangepartitioning(customer_state#105 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=4743]\n",
      "\n",
      "(7) Sort\n",
      "Input [2]: [customer_state#105, count#8384L]\n",
      "Arguments: [customer_state#105 ASC NULLS FIRST], true, 0\n",
      "\n",
      "(8) Project\n",
      "Output [2]: [CASE WHEN (customer_state#105 = AL) THEN null ELSE customer_state#105 END AS customer_state#8389, count#8384L]\n",
      "Input [2]: [customer_state#105, count#8384L]\n",
      "\n",
      "(9) AdaptiveSparkPlan\n",
      "Output [2]: [customer_state#8389, count#8384L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Explain\n",
    "(df_customers\n",
    "    .groupBy('customer_state')\n",
    "    .count()\n",
    "    .orderBy('customer_state')\n",
    "    .replace('AL', None)\n",
    "    .dropna(thresh=2)\n",
    "    .explain(mode='formatted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4c73f9ae",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|customer_state|   ct|\n",
      "+--------------+-----+\n",
      "|            SP|41746|\n",
      "|            RJ|12852|\n",
      "+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n",
      "+--------------+-----+\n",
      "|customer_state|   ct|\n",
      "+--------------+-----+\n",
      "|            SP|41746|\n",
      "|            RJ|12852|\n",
      "+--------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join\n",
    "(df_orders.join(df_customers, df_orders.customer_id == df_customers.customer_id, 'inner')\n",
    "    .select(\n",
    "        df_orders.order_id.alias(\"cupom_id\"),\n",
    "        df_customers.customer_state\n",
    "    )\n",
    "    .groupBy(\"customer_state\").agg(count(\"*\").alias(\"ct\"))\n",
    "    .sort(desc(\"ct\"))\n",
    "    .show(2))\n",
    "\n",
    "(df_orders.join(df_customers, 'customer_id')\n",
    "    .select(\n",
    "        df_orders.order_id.alias(\"cupom_id\"),\n",
    "        df_customers.customer_state\n",
    "    )\n",
    "    .groupBy(\"customer_state\").agg(count(\"*\").alias(\"ct\"))\n",
    "    .sort(desc(\"ct\"))\n",
    "    .show(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1db6f978",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (13)\n",
      "+- Sort (12)\n",
      "   +- Exchange (11)\n",
      "      +- HashAggregate (10)\n",
      "         +- Exchange (9)\n",
      "            +- HashAggregate (8)\n",
      "               +- Project (7)\n",
      "                  +- BroadcastHashJoin Inner BuildLeft (6)\n",
      "                     :- BroadcastExchange (3)\n",
      "                     :  +- Filter (2)\n",
      "                     :     +- Scan csv  (1)\n",
      "                     +- Filter (5)\n",
      "                        +- Scan csv  (4)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [1]: [customer_id#129]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/Users/gabrielbossardi/Documents/Projects/pyspark-overview/dataset/csv_data/olist_orders_dataset.csv]\n",
      "PushedFilters: [IsNotNull(customer_id)]\n",
      "ReadSchema: struct<customer_id:string>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [customer_id#129]\n",
      "Condition : isnotnull(customer_id#129)\n",
      "\n",
      "(3) BroadcastExchange\n",
      "Input [1]: [customer_id#129]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=6952]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [2]: [customer_id#101, customer_state#105]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/Users/gabrielbossardi/Documents/Projects/pyspark-overview/dataset/csv_data/olist_customers_dataset.csv]\n",
      "PushedFilters: [IsNotNull(customer_id)]\n",
      "ReadSchema: struct<customer_id:string,customer_state:string>\n",
      "\n",
      "(5) Filter\n",
      "Input [2]: [customer_id#101, customer_state#105]\n",
      "Condition : isnotnull(customer_id#101)\n",
      "\n",
      "(6) BroadcastHashJoin\n",
      "Left keys [1]: [customer_id#129]\n",
      "Right keys [1]: [customer_id#101]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) Project\n",
      "Output [1]: [customer_state#105]\n",
      "Input [3]: [customer_id#129, customer_id#101, customer_state#105]\n",
      "\n",
      "(8) HashAggregate\n",
      "Input [1]: [customer_state#105]\n",
      "Keys [1]: [customer_state#105]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#9421L]\n",
      "Results [2]: [customer_state#105, count#9422L]\n",
      "\n",
      "(9) Exchange\n",
      "Input [2]: [customer_state#105, count#9422L]\n",
      "Arguments: hashpartitioning(customer_state#105, 200), ENSURE_REQUIREMENTS, [plan_id=6957]\n",
      "\n",
      "(10) HashAggregate\n",
      "Input [2]: [customer_state#105, count#9422L]\n",
      "Keys [1]: [customer_state#105]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#9417L]\n",
      "Results [2]: [customer_state#105, count(1)#9417L AS ct#9418L]\n",
      "\n",
      "(11) Exchange\n",
      "Input [2]: [customer_state#105, ct#9418L]\n",
      "Arguments: rangepartitioning(ct#9418L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=6960]\n",
      "\n",
      "(12) Sort\n",
      "Input [2]: [customer_state#105, ct#9418L]\n",
      "Arguments: [ct#9418L DESC NULLS LAST], true, 0\n",
      "\n",
      "(13) AdaptiveSparkPlan\n",
      "Output [2]: [customer_state#105, ct#9418L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (13)\n",
      "+- Sort (12)\n",
      "   +- Exchange (11)\n",
      "      +- HashAggregate (10)\n",
      "         +- Exchange (9)\n",
      "            +- HashAggregate (8)\n",
      "               +- Project (7)\n",
      "                  +- BroadcastHashJoin Inner BuildRight (6)\n",
      "                     :- Filter (2)\n",
      "                     :  +- Scan csv  (1)\n",
      "                     +- BroadcastExchange (5)\n",
      "                        +- Filter (4)\n",
      "                           +- Scan csv  (3)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [1]: [customer_id#129]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/Users/gabrielbossardi/Documents/Projects/pyspark-overview/dataset/csv_data/olist_orders_dataset.csv]\n",
      "PushedFilters: [IsNotNull(customer_id)]\n",
      "ReadSchema: struct<customer_id:string>\n",
      "\n",
      "(2) Filter\n",
      "Input [1]: [customer_id#129]\n",
      "Condition : isnotnull(customer_id#129)\n",
      "\n",
      "(3) Scan csv \n",
      "Output [2]: [customer_id#101, customer_state#105]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [file:/Users/gabrielbossardi/Documents/Projects/pyspark-overview/dataset/csv_data/olist_customers_dataset.csv]\n",
      "PushedFilters: [IsNotNull(customer_id)]\n",
      "ReadSchema: struct<customer_id:string,customer_state:string>\n",
      "\n",
      "(4) Filter\n",
      "Input [2]: [customer_id#101, customer_state#105]\n",
      "Condition : isnotnull(customer_id#101)\n",
      "\n",
      "(5) BroadcastExchange\n",
      "Input [2]: [customer_id#101, customer_state#105]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, false]),false), [plan_id=7002]\n",
      "\n",
      "(6) BroadcastHashJoin\n",
      "Left keys [1]: [customer_id#129]\n",
      "Right keys [1]: [customer_id#101]\n",
      "Join type: Inner\n",
      "Join condition: None\n",
      "\n",
      "(7) Project\n",
      "Output [1]: [customer_state#105]\n",
      "Input [3]: [customer_id#129, customer_id#101, customer_state#105]\n",
      "\n",
      "(8) HashAggregate\n",
      "Input [1]: [customer_state#105]\n",
      "Keys [1]: [customer_state#105]\n",
      "Functions [1]: [partial_count(1)]\n",
      "Aggregate Attributes [1]: [count#9458L]\n",
      "Results [2]: [customer_state#105, count#9459L]\n",
      "\n",
      "(9) Exchange\n",
      "Input [2]: [customer_state#105, count#9459L]\n",
      "Arguments: hashpartitioning(customer_state#105, 200), ENSURE_REQUIREMENTS, [plan_id=7007]\n",
      "\n",
      "(10) HashAggregate\n",
      "Input [2]: [customer_state#105, count#9459L]\n",
      "Keys [1]: [customer_state#105]\n",
      "Functions [1]: [count(1)]\n",
      "Aggregate Attributes [1]: [count(1)#9454L]\n",
      "Results [2]: [customer_state#105, count(1)#9454L AS ct#9455L]\n",
      "\n",
      "(11) Exchange\n",
      "Input [2]: [customer_state#105, ct#9455L]\n",
      "Arguments: rangepartitioning(ct#9455L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=7010]\n",
      "\n",
      "(12) Sort\n",
      "Input [2]: [customer_state#105, ct#9455L]\n",
      "Arguments: [ct#9455L DESC NULLS LAST], true, 0\n",
      "\n",
      "(13) AdaptiveSparkPlan\n",
      "Output [2]: [customer_state#105, ct#9455L]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# without hint\n",
    "(df_orders.join(df_customers, df_orders.customer_id == df_customers.customer_id, 'inner')\n",
    "    .select(\n",
    "        df_orders.order_id.alias(\"cupom_id\"),\n",
    "        df_customers.customer_state\n",
    "    )\n",
    "    .groupBy(\"customer_state\").agg(count(\"*\").alias(\"ct\"))\n",
    "    .sort(desc(\"ct\"))\n",
    "    .explain(mode=\"formatted\"))\n",
    "\n",
    "# hint\n",
    "(df_orders.join(df_customers.hint(\"broadcast\"), df_orders.customer_id == df_customers.customer_id, 'inner')\n",
    "    .select(\n",
    "        df_orders.order_id.alias(\"cupom_id\"),\n",
    "        df_customers.customer_state\n",
    "    )\n",
    "    .groupBy(\"customer_state\").agg(count(\"*\").alias(\"ct\"))\n",
    "    .sort(desc(\"ct\"))\n",
    "    .explain(mode=\"formatted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "62ac13df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: string, customer_unique_id: string, customer_zip_code_prefix: int, customer_city: string, customer_state: string]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# persist\n",
    "df_customers.persist(StorageLevel.MEMORY_ONLY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80c8da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
